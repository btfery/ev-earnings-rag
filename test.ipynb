{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35581e89",
   "metadata": {},
   "source": [
    "# 1 - Main components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de127469",
   "metadata": {},
   "source": [
    "## Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22646bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load the variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize your model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e3ad6",
   "metadata": {},
   "source": [
    "## Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab88d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04104c44",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebda505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"earnings_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a7353",
   "metadata": {},
   "source": [
    "# 2 - Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792432a",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and goodbye.\n",
      "\n",
      "**Vaibhav Taneja:** Alright. Cool.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"transcripts/TSLA_Q4_2025.json\",\n",
    "    # '.' refers to the root object of the JSON file\n",
    "    jq_schema=\".\", \n",
    "    # Use the dot-notation path directly in the content_key\n",
    "    content_key=\"full_conference_call_transcript\",\n",
    "    text_content=True\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3b037f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents.\n",
      "Source: /Users/blakefery/ml-workspace/ev-earnings-rag/transcripts/TSLA_Q4_2025.json\n",
      "Excerpt: **Elon Musk:** Thanks, Travis. So I have updated t...\n",
      "\n",
      "Source: /Users/blakefery/ml-workspace/ev-earnings-rag/transcripts/RIVN_Q4_2025.json\n",
      "Excerpt: Robert Scaringe: Thanks, Chip. Good afternoon, eve...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
    "\n",
    "# 1. Define the parameters for each JSON file\n",
    "loader_kwargs = {\n",
    "    \"jq_schema\": \".\",\n",
    "    \"content_key\": \"full_conference_call_transcript\",\n",
    "    \"text_content\": True\n",
    "}\n",
    "\n",
    "# 2. Use DirectoryLoader to find all .json files in your transcripts folder\n",
    "loader = DirectoryLoader(\n",
    "    path=\"./transcripts/\",\n",
    "    glob=\"*.json\",\n",
    "    loader_cls=JSONLoader,\n",
    "    loader_kwargs=loader_kwargs\n",
    ")\n",
    "\n",
    "# 3. Load all files into a single list of documents\n",
    "docs = loader.load()\n",
    "\n",
    "# Check how many documents were loaded\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "# Accessing content from different files\n",
    "for doc in docs:\n",
    "    print(f\"Source: {doc.metadata.get('source')}\")\n",
    "    print(f\"Excerpt: {doc.page_content[:50]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53f538",
   "metadata": {},
   "source": [
    "## Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "838c3c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split earnings into 136 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split earnings into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7e99f",
   "metadata": {},
   "source": [
    "## Storing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5a9db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05ed1ec8-2ddc-4da1-97b7-95b75d48602b', 'eb99ec01-6d51-4e16-8e57-502406bb597d', '16a04be4-b00c-447b-92df-91535719ee31']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c48cb943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "print(len(document_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96501f2",
   "metadata": {},
   "source": [
    "# 3 - Retrieval and generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e5190",
   "metadata": {},
   "source": [
    "## RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35cc044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c8e6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from company earnings calls transcripts. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a0415d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the first comment Robert Scaringe makes?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (bc82bfc7-dc96-4e9a-bd4c-041d65203cb2)\n",
      " Call ID: bc82bfc7-dc96-4e9a-bd4c-041d65203cb2\n",
      "  Args:\n",
      "    query: What is the first comment Robert Scaringe makes?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'seq_num': 1, 'start_index': 0, 'source': '/Users/blakefery/ml-workspace/ev-earnings-rag/transcripts/RIVN_Q4_2025.json'}\n",
      "Content: Robert Scaringe: Thanks, Chip. Good afternoon, everyone, and thanks for joining us for today's call. 2025 was a year focused on execution at Rivian as we laid the foundations for scaling our business. Our team progressed the development of our technology road map in R2, while simultaneously driving continued improvement in our customer experience and our path to profitability. In founding Rivian, I wanted to demonstrate how a clean sheet technology-focused vehicle could eliminate long accepted compromises and provide consumers choice. Our goal with the launch of our R1 products was to establish the Rivian brand by delivering a combination of efficiency, on-road performance, off-road capability, functional utility and product refinement that simply didn't exist in the market.\n",
      "\n",
      "Source: {'source': '/Users/blakefery/ml-workspace/ev-earnings-rag/transcripts/RIVN_Q4_2025.json', 'start_index': 13070, 'seq_num': 1}\n",
      "Content: Robert Scaringe: Dan, thanks for the question. With regards to R2, I've had chance to spend a lot of time in it over the last several months and really over the last month or so, driving our validation vehicles that are produced in our plant off of our manufacturing validation build. And the vehicle is just absolutely incredible. It's the combination of features, the packaging, the vehicle dynamics, the steering wheel, we're incredibly bullish on. And as I talked about a lot in the past, we ultimately think the market is really hungry for some choice in this segment.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Robert Scaringe's first comment is: \"Thanks, Chip. Good afternoon, everyone, and thanks for joining us for today's call. 2025 was a year focused on execution at Rivian as we laid the foundations for scaling our business. Our team progressed the development of our technology road map in R2, while simultaneously driving continued improvement in our customer experience and our path to profitability. In founding Rivian, I wanted to demonstrate how a clean sheet technology-focused vehicle could eliminate long accepted compromises and provide consumers choice. Our goal with the launch of our R1 products was to establish the Rivian brand by delivering a combination of efficiency, on-road performance, off-road capability, functional utility and product refinement that simply didn't exist in the market.\"\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is the first comment Robert Scaringe makes?\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0de21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev-earnings-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
